# Curso CODER - DataScience-II

Predicci칩n de Precios de Propiedades en California
Este proyecto de Data Science tiene como objetivo construir un modelo de Machine Learning para predecir el precio de propiedades en California. A partir de un an치lisis exhaustivo de datos y el uso de m칰ltiples algoritmos de regresi칩n, se logr칩 identificar los factores clave que determinan el precio de las viviendas y seleccionar el modelo m치s eficiente para esta tarea.

## 游늵 Contenido del Proyecto

EDA (Exploratory Data Analysis): Visualizaci칩n y an치lisis de las principales caracter칤sticas del dataset.
Limpieza de Datos: Tratamiento de valores at칤picos mediante IsolationForest.
Transformaciones: Encoding de variables categ칩ricas, escalamiento de datos y PCA.
Modelado: Evaluaci칩n de modelos como KNN, Linear Regression y XGBoost.
Optimizaci칩n: Ajuste de hiperpar치metros usando Halving Grid Search y validaci칩n cruzada.
Resultados: Evaluaci칩n mediante m칠tricas como R y MSE.

## 丘뙖잺 Requisitos de Instalaci칩n

Para ejecutar este proyecto, aseg칰rate de tener instaladas las siguientes librer칤as:

pip install pandas numpy matplotlib seaborn scikit-learn xgboost lazypredict

## 游닄 Librer칤as Utilizadas

import pandas as pd  
import numpy as np  
import matplotlib.pyplot as plt  
import seaborn as sns  
from sklearn.preprocessing import OrdinalEncoder, LabelEncoder, StandardScaler  
from sklearn.model_selection import train_test_split, cross_val_score, HalvingGridSearchCV  
from sklearn.decomposition import PCA  
from sklearn.linear_model import LinearRegression  
from sklearn.neighbors import KNeighborsRegressor  
from sklearn.metrics import mean_squared_error, r2_score  
from xgboost import XGBRegressor  
from lazypredict.Supervised import LazyRegressor

## 游 Ejecuci칩n
### Clona este repositorio:

git clone <https://github.com/djender985/>
cd <CursoDataScience-II>

### Instala las dependencias necesarias:

pip install -r requirements.txt

Abre y ejecuta el Jupyter Notebook para reproducir el an치lisis y entrenamiento de modelos.


## 游늳 Resultados
El modelo m치s eficiente fue XGBoost, alcanzando un R de 0.84 despu칠s de la optimizaci칩n de hiperpar치metros.
